# classic Machine Learning Algorithms

  
<h1> <a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html"> Linear Regression </a></h1>
  <h4>
  <font size="4" face="Times New Roma" color="#3f134f"> 
    <ul style="margin-left: 30px">
      <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#simple~linear~regression">Simple Linear Regression </a> </li> <br>
      <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#grad~sim~linear">Gradient Descent over simple linear regression</a> </li> <br>
      <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#learning-rate">Effect of different values for learning rate</a> </li> <br>
      <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#m-linear-r">Multiple Linear Regression</a> </li> <br>
    <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#impl-multi">Implementation of gradient descent for Multiple Linear regression using NUMPY</a> </li> <br>
     <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#insurence">Test of our implemntation in 'insurance.csv' dataset </a> </li> <br>
     <li><a href="https://daodavid.github.io/classic-ML/notes/linear-regression.html#MLE">The probabilistic approach to linear regression.Maximum likelihood estimation </a> </li> <br>
</ul> 
</font>
 </h4>
